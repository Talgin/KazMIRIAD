{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b059c15-b843-440e-bd9d-e1ad952ca912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Authentication ---\n",
    "# This script assumes you have authenticated via `gcloud auth application-default login`.\n",
    "# The library will automatically find your credentials.\n",
    "# If you need to use a service account key, uncomment the following line:\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your/key.json'\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import translate_v2 as translate\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "\n",
    "# --- Configuration ---\n",
    "# TODO: Update these variables with your specific details\n",
    "GCP_PROJECT_ID = \"argon-bulwark-468319-h7\"  # Replace with your Google Cloud Project ID\n",
    "INPUT_CSV_PATH = \"./data/MIRIAD4_4_dataset.csv\"\n",
    "OUTPUT_CSV_PATH = \"./data/miriad_dataset_translated_kk.csv\"\n",
    "COLUMNS_TO_TRANSLATE = ['question', 'answer']\n",
    "TARGET_LANGUAGE = 'kk' # ISO 639-1 code for Kazakh\n",
    "SAVE_CHECKPOINT_FREQUENCY = 100 # How often to save progress (in number of rows)\n",
    "LOG_FREQUENCY = 1000 # How often to log progress summary (in number of rows)\n",
    "LOG_FILE = \"translation_progress.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d22595-59c6-40fc-80e1-3c80d9f6293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Logging Setup ---\n",
    "# Configures a logger to write to a file and the console.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(LOG_FILE),\n",
    "        logging.StreamHandler() # To also print logs to the console/notebook output\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e8ea7-6973-41ae-a329-65ace63725cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Authentication ---\n",
    "logging.info(\"Initializing Google Translate client...\")\n",
    "try:\n",
    "    translate_client = translate.Client()\n",
    "    logging.info(\"Client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logging.critical(f\"Fatal: Error initializing client. Make sure you have authenticated and enabled the API. Details: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391c648-36f2-4c19-801d-1f137d8916a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Translation Function ---\n",
    "def translate_text(text, target_language):\n",
    "    \"\"\"Translates a single text string using the Google Translate API.\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    try:\n",
    "        result = translate_client.translate(text, target_language=target_language)\n",
    "        return result['translatedText']\n",
    "    except Exception as e:\n",
    "        # Log the error with more detail\n",
    "        logging.error(f\"Translation API error for text '{text[:70]}...': {e}\")\n",
    "        return \"TRANSLATION_ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67584006-ae3b-4b57-9318-ebbbe55ef703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading & Resume Logic ---\n",
    "start_index = 0\n",
    "total_chars_sent = 0\n",
    "total_chars_translated = 0\n",
    "try:\n",
    "    source_df = pd.read_csv(INPUT_CSV_PATH)\n",
    "    logging.info(f\"Successfully loaded {len(source_df)} rows from source file '{INPUT_CSV_PATH}'.\")\n",
    "\n",
    "    if os.path.exists(OUTPUT_CSV_PATH):\n",
    "        logging.info(f\"Found existing output file at '{OUTPUT_CSV_PATH}'.\")\n",
    "        processed_df = pd.read_csv(OUTPUT_CSV_PATH)\n",
    "        start_index = len(processed_df)\n",
    "        logging.info(f\"Output file has {start_index} rows. These will be checked for completeness.\")\n",
    "\n",
    "        # --- Recalculate character counts from the existing file ---\n",
    "        logging.info(\"Calculating character counts from previously translated rows...\")\n",
    "        question_trans_col = f'question_{TARGET_LANGUAGE}'\n",
    "        answer_trans_col = f'answer_{TARGET_LANGUAGE}'\n",
    "        \n",
    "        if question_trans_col in processed_df.columns:\n",
    "            q_translated = processed_df[processed_df[question_trans_col].notna()]\n",
    "            total_chars_sent += q_translated['question'].astype(str).str.len().sum()\n",
    "            total_chars_translated += q_translated[question_trans_col].astype(str).str.len().sum()\n",
    "\n",
    "        if answer_trans_col in processed_df.columns:\n",
    "            a_translated = processed_df[processed_df[answer_trans_col].notna()]\n",
    "            total_chars_sent += a_translated['answer'].astype(str).str.len().sum()\n",
    "            total_chars_translated += a_translated[answer_trans_col].astype(str).str.len().sum()\n",
    "        \n",
    "        logging.info(f\"Resuming with {total_chars_sent:,} characters already sent and {total_chars_translated:,} characters already translated.\")\n",
    "\n",
    "\n",
    "        # --- PHASE 1: Back-filling partially completed rows ---\n",
    "        if answer_trans_col not in processed_df.columns:\n",
    "            processed_df[answer_trans_col] = pd.NA\n",
    "\n",
    "        backfill_mask = processed_df[question_trans_col].notna() & processed_df[answer_trans_col].isna()\n",
    "        rows_to_backfill = processed_df[backfill_mask]\n",
    "\n",
    "        if not rows_to_backfill.empty:\n",
    "            logging.info(f\"Found {len(rows_to_backfill)} rows with translated questions but missing translated answers. Starting back-fill process.\")\n",
    "            for index, row in tqdm(rows_to_backfill.iterrows(), total=len(rows_to_backfill), desc=\"Back-filling Answers\"):\n",
    "                answer_text = row['answer']\n",
    "                if isinstance(answer_text, str):\n",
    "                    total_chars_sent += len(answer_text)\n",
    "                translated_answer = translate_text(answer_text, TARGET_LANGUAGE)\n",
    "                if isinstance(translated_answer, str) and translated_answer != \"TRANSLATION_ERROR\":\n",
    "                    total_chars_translated += len(translated_answer)\n",
                     else:\n",
                         break\n",
    "                processed_df.loc[index, answer_trans_col] = translated_answer\n",
    "            \n",
    "            logging.info(\"Back-fill complete. Overwriting the output file with completed rows to ensure consistency.\")\n",
    "            processed_df.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8')\n",
    "            logging.info(\"Overwrite complete.\")\n",
    "        else:\n",
    "            logging.info(\"No rows needed back-filling. All existing rows are complete.\")\n",
    "        \n",
    "        del processed_df # Free up memory\n",
    "    else:\n",
    "        logging.info(\"No existing output file found. Starting from scratch.\")\n",
    "        header_df = source_df.iloc[0:0].copy()\n",
    "        header_df[f'question_{TARGET_LANGUAGE}'] = pd.NA\n",
    "        header_df[f'answer_{TARGET_LANGUAGE}'] = pd.NA\n",
    "        header_df.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    logging.critical(f\"Fatal: The source file '{INPUT_CSV_PATH}' was not found. Please check the path.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    logging.critical(f\"Fatal: An error occurred during data loading or back-filling: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5c96c-ddc4-492d-b059-3a856a6f4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PHASE 2: Main Row-by-Row Processing Loop for new rows ---\n",
    "logging.info(f\"Starting new row translation from index {start_index}.\")\n",
    "rows_to_process = source_df.iloc[start_index:]\n",
    "\n",
    "if rows_to_process.empty:\n",
    "    logging.info(\"All rows have already been processed. Nothing to do.\")\n",
    "else:\n",
    "    processed_rows_buffer = []\n",
    "    total_rows_to_process = len(rows_to_process)\n",
    "    \n",
    "    with tqdm(total=total_rows_to_process, desc=\"Processing New Rows\") as pbar:\n",
    "        for index, row in rows_to_process.iterrows():\n",
    "            processed_row = row.copy()\n",
    "\n",
    "            # Translate Question\n",
    "            question_text = row['question']\n",
    "            if isinstance(question_text, str):\n",
    "                total_chars_sent += len(question_text)\n",
    "            translated_question = translate_text(question_text, TARGET_LANGUAGE)\n",
    "            if isinstance(translated_question, str) and translated_question != \"TRANSLATION_ERROR\":\n",
    "                total_chars_translated += len(translated_question)\n",
    "            processed_row[f'question_{TARGET_LANGUAGE}'] = translated_question\n",
    "\n",
    "            # Translate Answer\n",
    "            answer_text = row['answer']\n",
    "            if isinstance(answer_text, str):\n",
    "                total_chars_sent += len(answer_text)\n",
    "            translated_answer = translate_text(answer_text, TARGET_LANGUAGE)\n",
    "            if isinstance(translated_answer, str) and translated_answer != \"TRANSLATION_ERROR\":\n",
    "                total_chars_translated += len(translated_answer)\n",
    "            processed_row[f'answer_{TARGET_LANGUAGE}'] = translated_answer\n",
    "\n",
    "            processed_rows_buffer.append(processed_row)\n",
    "            \n",
    "            tqdm.write(\"=\"*100)\n",
    "            tqdm.write(f\"Row Index: {index} | qa_id: {row['qa_id']} | paper_id: {row['paper_id']}\")\n",
    "            tqdm.write(f\"  Original (question): {question_text}\")\n",
    "            tqdm.write(f\"Translated (question): {translated_question}\")\n",
    "            tqdm.write(f\"  Original (answer):   {answer_text}\")\n",
    "            tqdm.write(f\"Translated (answer):   {translated_answer}\")\n",
    "            tqdm.write(\"=\"*100)\n",
    "\n",
    "            # --- Checkpoint Saving ---\n",
    "            if len(processed_rows_buffer) >= SAVE_CHECKPOINT_FREQUENCY:\n",
    "                tqdm.write(f\"Checkpoint: Appending {len(processed_rows_buffer)} new rows to {OUTPUT_CSV_PATH}...\")\n",
    "                checkpoint_df = pd.DataFrame(processed_rows_buffer)\n",
    "                checkpoint_df.to_csv(OUTPUT_CSV_PATH, mode='a', header=False, index=False, encoding='utf-8')\n",
    "                processed_rows_buffer.clear()\n",
    "            \n",
    "            # --- Progress Logging ---\n",
    "            if (pbar.n + 1) % LOG_FREQUENCY == 0:\n",
    "                logging.info(f\"Progress Update: Processed {pbar.n + 1}/{total_rows_to_process} new rows. Total characters sent: {total_chars_sent:,}.\")\n",
    "S\n",
    "            pbar.set_description(f\"Processing Rows | Chars Sent: {total_chars_sent:,}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "    # --- Final Save ---\n",
    "    if processed_rows_buffer:\n",
    "        logging.info(f\"Saving remaining {len(processed_rows_buffer)} new rows.\")\n",
    "        final_df = pd.DataFrame(processed_rows_buffer)\n",
    "        final_df.to_csv(OUTPUT_CSV_PATH, mode='a', header=False, index=False, encoding='utf-8')\n",
    "        processed_rows_buffer.clear()\n",
    "\n",
    "logging.info(\"Translation process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0422e75b-273b-4b2c-84e8-f80627c5ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Summary ---\n",
    "logging.info(\"=\"*50)\n",
    "logging.info(\"--- FINAL SUMMARY ---\")\n",
    "logging.info(f\"Final translated data saved to {OUTPUT_CSV_PATH}\")\n",
    "logging.info(f\"Total characters sent for translation: {total_chars_sent:,}\")\n",
    "logging.info(f\"Total characters received after translation: {total_chars_translated:,}\")\n",
    "logging.info(\"=\"*50)\n",
    "print(\"\\nFinal dataset should be complete and located at:\", OUTPUT_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5290a35-b7ec-46f2-ad21-50d2f378ec10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e759c-0041-48dc-b6da-52a617e44ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23680413-ebff-4778-a5e0-7e0b2cbb2015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
